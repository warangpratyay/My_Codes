{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\ASK Computers\\Desktop\\CV Projects\\DeepLearningCV\\fer2013\\train'\n",
    "val_dir = r'C:\\Users\\ASK Computers\\Desktop\\CV Projects\\DeepLearningCV\\fer2013\\validation'\n",
    "img_rows = 48\n",
    "img_cols = 48\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/ 255.,\n",
    "                                   rotation_range = 30,\n",
    "                                   shear_range = 0.3,\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest'\n",
    "                                  )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1/ 255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31761 images belonging to 7 classes.\n",
      "Found 3974 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    color_mode = 'grayscale',\n",
    "                                                    target_size = (img_rows, img_cols),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    shuffle = True\n",
    "                                                   )\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                color_mode = 'grayscale',\n",
    "                                                target_size = (img_rows, img_cols),\n",
    "                                                batch_size = batch_size,\n",
    "                                                class_mode = 'categorical',\n",
    "                                                shuffle = True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 6,160,871\n",
      "Trainable params: 6,158,951\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation = 'elu', padding = 'same', input_shape = (img_rows, img_cols, 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), activation = 'elu', padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation = 'elu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(512, activation = 'elu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('Checkpoints/emotion_detector.h5',\n",
    "                             verbose = 1,\n",
    "                             monitor = 'val_loss',\n",
    "                             mode = 'min',\n",
    "                             save_best_only = True\n",
    "                            )\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                          verbose = 1,\n",
    "                          patience = 4,\n",
    "                          restore_best_weights = True\n",
    "                         )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.00001,\n",
    "                              patience = 2,\n",
    "                              factor = 0.3\n",
    "                             )\n",
    "\n",
    "callbacks = [checkpoint, earlystop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 993 steps, validate for 125 steps\n",
      "Epoch 1/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 2.0625 - accuracy: 0.1955\n",
      "Epoch 00001: val_loss improved from inf to 1.96635, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1495s 2s/step - loss: 2.0625 - accuracy: 0.1954 - val_loss: 1.9664 - val_accuracy: 0.1241\n",
      "Epoch 2/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.9432 - accuracy: 0.2028\n",
      "Epoch 00002: val_loss did not improve from 1.96635\n",
      "993/993 [==============================] - 1263s 1s/step - loss: 1.9433 - accuracy: 0.2028 - val_loss: 2.0927 - val_accuracy: 0.2235\n",
      "Epoch 3/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.9215 - accuracy: 0.2117\n",
      "Epoch 00003: val_loss improved from 1.96635 to 1.91797, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1091s 1s/step - loss: 1.9213 - accuracy: 0.2119 - val_loss: 1.9180 - val_accuracy: 0.2355\n",
      "Epoch 4/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.8857 - accuracy: 0.2386\n",
      "Epoch 00004: val_loss did not improve from 1.91797\n",
      "993/993 [==============================] - 1076s 1s/step - loss: 1.8855 - accuracy: 0.2388 - val_loss: 1.9353 - val_accuracy: 0.2446\n",
      "Epoch 5/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.8194 - accuracy: 0.2786\n",
      "Epoch 00005: val_loss improved from 1.91797 to 1.66450, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1049s 1s/step - loss: 1.8193 - accuracy: 0.2786 - val_loss: 1.6645 - val_accuracy: 0.3671\n",
      "Epoch 6/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.7167 - accuracy: 0.3356\n",
      "Epoch 00006: val_loss improved from 1.66450 to 1.59852, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1159s 1s/step - loss: 1.7168 - accuracy: 0.3355 - val_loss: 1.5985 - val_accuracy: 0.4170\n",
      "Epoch 7/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.6224 - accuracy: 0.3818\n",
      "Epoch 00007: val_loss did not improve from 1.59852\n",
      "993/993 [==============================] - 1093s 1s/step - loss: 1.6222 - accuracy: 0.3819 - val_loss: 1.6150 - val_accuracy: 0.4258\n",
      "Epoch 8/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.5536 - accuracy: 0.4106\n",
      "Epoch 00008: val_loss improved from 1.59852 to 1.52637, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1052s 1s/step - loss: 1.5533 - accuracy: 0.4107 - val_loss: 1.5264 - val_accuracy: 0.4255\n",
      "Epoch 9/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.5020 - accuracy: 0.4289\n",
      "Epoch 00009: val_loss did not improve from 1.52637\n",
      "993/993 [==============================] - 1046s 1s/step - loss: 1.5019 - accuracy: 0.4290 - val_loss: 1.5731 - val_accuracy: 0.4567\n",
      "Epoch 10/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.4732 - accuracy: 0.4445\n",
      "Epoch 00010: val_loss improved from 1.52637 to 1.49131, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1053s 1s/step - loss: 1.4733 - accuracy: 0.4444 - val_loss: 1.4913 - val_accuracy: 0.4519\n",
      "Epoch 11/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.4425 - accuracy: 0.4576\n",
      "Epoch 00011: val_loss improved from 1.49131 to 1.46334, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1058s 1s/step - loss: 1.4427 - accuracy: 0.4575 - val_loss: 1.4633 - val_accuracy: 0.4685\n",
      "Epoch 12/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.4197 - accuracy: 0.4638\n",
      "Epoch 00012: val_loss did not improve from 1.46334\n",
      "993/993 [==============================] - 1103s 1s/step - loss: 1.4198 - accuracy: 0.4638 - val_loss: 1.5429 - val_accuracy: 0.4716\n",
      "Epoch 13/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.3960 - accuracy: 0.4746\n",
      "Epoch 00013: val_loss did not improve from 1.46334\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "993/993 [==============================] - 1073s 1s/step - loss: 1.3961 - accuracy: 0.4746 - val_loss: 1.5018 - val_accuracy: 0.4721\n",
      "Epoch 14/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2921 - accuracy: 0.5130\n",
      "Epoch 00014: val_loss improved from 1.46334 to 1.42038, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1124s 1s/step - loss: 1.2921 - accuracy: 0.5131 - val_loss: 1.4204 - val_accuracy: 0.5078\n",
      "Epoch 15/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2672 - accuracy: 0.5203\n",
      "Epoch 00015: val_loss improved from 1.42038 to 1.41888, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1147s 1s/step - loss: 1.2670 - accuracy: 0.5203 - val_loss: 1.4189 - val_accuracy: 0.4980\n",
      "Epoch 16/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2593 - accuracy: 0.5244\n",
      "Epoch 00016: val_loss improved from 1.41888 to 1.41649, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1178s 1s/step - loss: 1.2592 - accuracy: 0.5244 - val_loss: 1.4165 - val_accuracy: 0.5045\n",
      "Epoch 17/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2448 - accuracy: 0.5284\n",
      "Epoch 00017: val_loss did not improve from 1.41649\n",
      "993/993 [==============================] - 1196s 1s/step - loss: 1.2448 - accuracy: 0.5284 - val_loss: 1.4667 - val_accuracy: 0.4925\n",
      "Epoch 18/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2399 - accuracy: 0.5317\n",
      "Epoch 00018: val_loss improved from 1.41649 to 1.39659, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1059s 1s/step - loss: 1.2397 - accuracy: 0.5318 - val_loss: 1.3966 - val_accuracy: 0.5219\n",
      "Epoch 19/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2260 - accuracy: 0.5351\n",
      "Epoch 00019: val_loss did not improve from 1.39659\n",
      "993/993 [==============================] - 1061s 1s/step - loss: 1.2259 - accuracy: 0.5353 - val_loss: 1.4055 - val_accuracy: 0.5342\n",
      "Epoch 20/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2153 - accuracy: 0.5428\n",
      "Epoch 00020: val_loss improved from 1.39659 to 1.39423, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1065s 1s/step - loss: 1.2153 - accuracy: 0.5428 - val_loss: 1.3942 - val_accuracy: 0.5304\n",
      "Epoch 21/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.2039 - accuracy: 0.5473\n",
      "Epoch 00021: val_loss did not improve from 1.39423\n",
      "993/993 [==============================] - 1066s 1s/step - loss: 1.2044 - accuracy: 0.5471 - val_loss: 1.4004 - val_accuracy: 0.5337\n",
      "Epoch 22/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1975 - accuracy: 0.5482\n",
      "Epoch 00022: val_loss improved from 1.39423 to 1.38580, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1063s 1s/step - loss: 1.1974 - accuracy: 0.5483 - val_loss: 1.3858 - val_accuracy: 0.5360\n",
      "Epoch 23/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1896 - accuracy: 0.5508\n",
      "Epoch 00023: val_loss did not improve from 1.38580\n",
      "993/993 [==============================] - 1054s 1s/step - loss: 1.1894 - accuracy: 0.5509 - val_loss: 1.4168 - val_accuracy: 0.5166\n",
      "Epoch 24/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1801 - accuracy: 0.5571\n",
      "Epoch 00024: val_loss did not improve from 1.38580\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "993/993 [==============================] - 1074s 1s/step - loss: 1.1800 - accuracy: 0.5570 - val_loss: 1.3887 - val_accuracy: 0.5199\n",
      "Epoch 25/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1492 - accuracy: 0.5681\n",
      "Epoch 00025: val_loss improved from 1.38580 to 1.37000, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1063s 1s/step - loss: 1.1490 - accuracy: 0.5681 - val_loss: 1.3700 - val_accuracy: 0.5415\n",
      "Epoch 26/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1403 - accuracy: 0.5708\n",
      "Epoch 00026: val_loss improved from 1.37000 to 1.34941, saving model to Checkpoints/emotion_detector.h5\n",
      "993/993 [==============================] - 1083s 1s/step - loss: 1.1405 - accuracy: 0.5707 - val_loss: 1.3494 - val_accuracy: 0.5455\n",
      "Epoch 27/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1409 - accuracy: 0.5729\n",
      "Epoch 00027: val_loss did not improve from 1.34941\n",
      "993/993 [==============================] - 1100s 1s/step - loss: 1.1407 - accuracy: 0.5729 - val_loss: 1.3685 - val_accuracy: 0.5408\n",
      "Epoch 28/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1300 - accuracy: 0.5743\n",
      "Epoch 00028: val_loss did not improve from 1.34941\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "993/993 [==============================] - 1059s 1s/step - loss: 1.1302 - accuracy: 0.5741 - val_loss: 1.3559 - val_accuracy: 0.5503\n",
      "Epoch 29/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1309 - accuracy: 0.5779\n",
      "Epoch 00029: val_loss did not improve from 1.34941\n",
      "993/993 [==============================] - 1056s 1s/step - loss: 1.1309 - accuracy: 0.5778 - val_loss: 1.3523 - val_accuracy: 0.5471\n",
      "Epoch 30/50\n",
      "992/993 [============================>.] - ETA: 1s - loss: 1.1249 - accuracy: 0.5764\n",
      "Epoch 00030: val_loss did not improve from 1.34941\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "993/993 [==============================] - 1049s 1s/step - loss: 1.1251 - accuracy: 0.5764 - val_loss: 1.3582 - val_accuracy: 0.5455\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "\n",
    "history = model.fit(train_generator, epochs = max_epochs, validation_data = (val_generator), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3974 images belonging to 7 classes.\n",
      "Confusion Matrix\n",
      "[[218  31  63  12  95  67   5]\n",
      " [ 64 344  16  16   0   0   0]\n",
      " [ 82  16 142  17 112 114  45]\n",
      " [ 14   5  22 750  66  12  10]\n",
      " [ 76  25  55 151 174  95  50]\n",
      " [ 41  14  30  28 195 279   7]\n",
      " [  9   9  87  28  21   1 261]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.43      0.44      0.44       491\n",
      "     Disgust       0.77      0.78      0.78       440\n",
      "        Fear       0.34      0.27      0.30       528\n",
      "       Happy       0.75      0.85      0.80       879\n",
      "     Neutral       0.26      0.28      0.27       626\n",
      "         Sad       0.49      0.47      0.48       594\n",
      "    Surprise       0.69      0.63      0.66       416\n",
      "\n",
      "    accuracy                           0.55      3974\n",
      "   macro avg       0.53      0.53      0.53      3974\n",
      "weighted avg       0.54      0.55      0.54      3974\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_train_samples = 31761\n",
    "nb_val_samples = 3974\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                       color_mode = 'grayscale',\n",
    "                                                       target_size = (img_rows, img_cols),\n",
    "                                                       batch_size = batch_size,\n",
    "                                                       class_mode = 'categorical',\n",
    "                                                       shuffle = False\n",
    "                                                      )\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#classification report & confusion matrix\n",
    "\n",
    "Y_pred = model.predict(validation_generator)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names = target_names))\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation = 'nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation = 90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "classifier = load_model('Checkpoints/emotion_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3974 images belonging to 7 classes.\n",
      "{0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(r'C:\\Users\\ASK Computers\\Desktop\\CV Projects\\DeepLearningCV\\18 . Deep Survaliance - Build a Face Detector with Emotion, Age and Gender Recognition\\Haarcascades\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    rect, face, image = face_detector(frame)\n",
    "    if np.sum([face]) != 0.0:\n",
    "        roi = face.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "        preds = classifier.predict(roi)[0]\n",
    "        label = class_labels[preds.argmax()]  \n",
    "        label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "        cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "    else:\n",
    "        cv2.putText(image, \"No Face Found\", (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "        \n",
    "    cv2.imshow('All', image)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
